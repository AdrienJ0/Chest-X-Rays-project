{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n%matplotlib inline\n \nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nfrom glob import glob \nfrom PIL import Image\nimport tensorflow as tf \nimport cv2\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping , ReduceLROnPlateau\nimport datetime\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nall_xray = pd.read_csv('../input/data/Data_Entry_2017.csv')\nbbox_list = pd.read_csv('/kaggle/input/data/BBox_List_2017.csv')\n\n\nall_xray.sample(5)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-06T18:44:51.500049Z","iopub.execute_input":"2023-11-06T18:44:51.500755Z","iopub.status.idle":"2023-11-06T18:45:00.537972Z","shell.execute_reply.started":"2023-11-06T18:44:51.500723Z","shell.execute_reply":"2023-11-06T18:45:00.537026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Exploration","metadata":{}},{"cell_type":"code","source":"all_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'data',  'images*', '*', '*.png'))}\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray.shape[0])\nall_xray['path'] = all_xray['Image Index'].map(all_image_paths.get)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:00.539450Z","iopub.execute_input":"2023-11-06T18:45:00.539745Z","iopub.status.idle":"2023-11-06T18:45:05.037444Z","shell.execute_reply.started":"2023-11-06T18:45:00.539719Z","shell.execute_reply":"2023-11-06T18:45:05.036516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_xray[\"Finding Labels\"].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.040379Z","iopub.execute_input":"2023-11-06T18:45:05.040696Z","iopub.status.idle":"2023-11-06T18:45:05.059450Z","shell.execute_reply.started":"2023-11-06T18:45:05.040654Z","shell.execute_reply":"2023-11-06T18:45:05.058563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = all_xray['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1, 1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts)) + 0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.062095Z","iopub.execute_input":"2023-11-06T18:45:05.062634Z","iopub.status.idle":"2023-11-06T18:45:05.454632Z","shell.execute_reply.started":"2023-11-06T18:45:05.062607Z","shell.execute_reply":"2023-11-06T18:45:05.453722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_labels = list(bbox_list[\"Finding Label\"].unique())\nbbox_labels","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.455857Z","iopub.execute_input":"2023-11-06T18:45:05.456144Z","iopub.status.idle":"2023-11-06T18:45:05.464576Z","shell.execute_reply.started":"2023-11-06T18:45:05.456119Z","shell.execute_reply":"2023-11-06T18:45:05.463688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_list.sample(5)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.465753Z","iopub.execute_input":"2023-11-06T18:45:05.466531Z","iopub.status.idle":"2023-11-06T18:45:05.481498Z","shell.execute_reply.started":"2023-11-06T18:45:05.466498Z","shell.execute_reply":"2023-11-06T18:45:05.480657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bbox_list['Finding Label'].value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.482618Z","iopub.execute_input":"2023-11-06T18:45:05.482971Z","iopub.status.idle":"2023-11-06T18:45:05.493862Z","shell.execute_reply.started":"2023-11-06T18:45:05.482940Z","shell.execute_reply":"2023-11-06T18:45:05.492975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_counts = bbox_list['Finding Label'].value_counts()\nfig, ax1 = plt.subplots(1, 1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts)) + 0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts)) + 0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.495067Z","iopub.execute_input":"2023-11-06T18:45:05.495316Z","iopub.status.idle":"2023-11-06T18:45:05.722197Z","shell.execute_reply.started":"2023-11-06T18:45:05.495294Z","shell.execute_reply":"2023-11-06T18:45:05.721308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"A = all_xray.set_index('Image Index')\nB = bbox_list.set_index('Image Index')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.723596Z","iopub.execute_input":"2023-11-06T18:45:05.724266Z","iopub.status.idle":"2023-11-06T18:45:05.759611Z","shell.execute_reply.started":"2023-11-06T18:45:05.724231Z","shell.execute_reply":"2023-11-06T18:45:05.758855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = B.join(A, how = \"inner\")\ndata = data.reset_index(drop = False)\ndata = data.drop(['Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 11'], axis = 1)\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:05.763067Z","iopub.execute_input":"2023-11-06T18:45:05.763349Z","iopub.status.idle":"2023-11-06T18:45:06.003592Z","shell.execute_reply.started":"2023-11-06T18:45:05.763324Z","shell.execute_reply":"2023-11-06T18:45:06.002664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.004908Z","iopub.execute_input":"2023-11-06T18:45:06.005613Z","iopub.status.idle":"2023-11-06T18:45:06.045061Z","shell.execute_reply.started":"2023-11-06T18:45:06.005580Z","shell.execute_reply":"2023-11-06T18:45:06.044133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.046167Z","iopub.execute_input":"2023-11-06T18:45:06.046468Z","iopub.status.idle":"2023-11-06T18:45:06.053838Z","shell.execute_reply.started":"2023-11-06T18:45:06.046442Z","shell.execute_reply":"2023-11-06T18:45:06.052944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[:, 'Bbox [x':'h]']","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.054992Z","iopub.execute_input":"2023-11-06T18:45:06.055296Z","iopub.status.idle":"2023-11-06T18:45:06.073464Z","shell.execute_reply.started":"2023-11-06T18:45:06.055268Z","shell.execute_reply":"2023-11-06T18:45:06.072531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows = 2, ncols = 4, figsize = (15, 10), subplot_kw = {'xticks':[], 'yticks':[]})\nfor i, ax in enumerate(axes.flat):\n    img = cv2.imread(data.loc[i, 'path'])\n    cv2.rectangle(img, (int(data.iloc[i, 2:6][0]), int(data.iloc[i, 2:6][1])), (int(data.iloc[i, 2:6][0] + data.iloc[i, 2:6][2]), int(data.iloc[i, 2:6][1] + data.iloc[i, 2:6][3])), (255, 0, 0), 10)\n    img = cv2.resize(img, (80, 80))\n    ax.imshow(img)\n    ax.set_title(data.loc[i, 'Finding Label'])\nfig.tight_layout()    \n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.074572Z","iopub.execute_input":"2023-11-06T18:45:06.074910Z","iopub.status.idle":"2023-11-06T18:45:06.799188Z","shell.execute_reply.started":"2023-11-06T18:45:06.074879Z","shell.execute_reply":"2023-11-06T18:45:06.798227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Because we'll split the data we must identify patient overlap ( check to see if a patient's ID appears in both the training set and the test set )**","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, roc_curve, auc, precision_recall_curve, average_precision_score\n\ntrain_data, val_data = train_test_split(data, test_size=0.2 , random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.800546Z","iopub.execute_input":"2023-11-06T18:45:06.800930Z","iopub.status.idle":"2023-11-06T18:45:06.938098Z","shell.execute_reply.started":"2023-11-06T18:45:06.800894Z","shell.execute_reply":"2023-11-06T18:45:06.937085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\" Train data shape : {train_data.shape} , Test Data shape : {val_data.shape} \")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.939257Z","iopub.execute_input":"2023-11-06T18:45:06.939546Z","iopub.status.idle":"2023-11-06T18:45:06.944304Z","shell.execute_reply.started":"2023-11-06T18:45:06.939521Z","shell.execute_reply":"2023-11-06T18:45:06.943458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Extract and compare the PatientId columns from the train and validation sets :\n\n1. **Extract patient IDs from the train and validation sets**\n2. **Convert these arrays of numbers into set() datatypes for easy comparison**\n3. **Identify patient overlap in the intersection of the two sets**","metadata":{}},{"cell_type":"code","source":"# Extract patient id's for the training set\nids_train = train_data['Patient ID'].values\n# Extract patient id's for the validation set\nids_valid = val_data['Patient ID'].values","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.945396Z","iopub.execute_input":"2023-11-06T18:45:06.945664Z","iopub.status.idle":"2023-11-06T18:45:06.954341Z","shell.execute_reply.started":"2023-11-06T18:45:06.945642Z","shell.execute_reply":"2023-11-06T18:45:06.953567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a \"set\" datastructure of the training set id's to identify unique id's\nids_train_set = set(ids_train)\nprint(f'There are {len(ids_train_set)} unique Patient IDs in the training set')\n# Create a \"set\" datastructure of the validation set id's to identify unique id's\nids_valid_set = set(ids_valid)\nprint(f'There are {len(ids_valid_set)} unique Patient IDs in the validation set')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.955511Z","iopub.execute_input":"2023-11-06T18:45:06.955861Z","iopub.status.idle":"2023-11-06T18:45:06.965309Z","shell.execute_reply.started":"2023-11-06T18:45:06.955830Z","shell.execute_reply":"2023-11-06T18:45:06.964563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Identify patient overlap by looking at the intersection between the sets\npatient_overlap = list(ids_train_set.intersection(ids_valid_set))\nn_overlap = len(patient_overlap)\nprint(f'There are {n_overlap} Patient IDs in both the training and validation sets')\nprint('')\nprint(f'These patients are in both the training and validation datasets:')\nprint(f'{patient_overlap}')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.966271Z","iopub.execute_input":"2023-11-06T18:45:06.966510Z","iopub.status.idle":"2023-11-06T18:45:06.979521Z","shell.execute_reply.started":"2023-11-06T18:45:06.966489Z","shell.execute_reply":"2023-11-06T18:45:06.978654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_overlap_idxs = []\nvalid_overlap_idxs = []\nfor idx in range(n_overlap):\n    train_overlap_idxs.extend(train_data.index[train_data['Patient ID'] == patient_overlap[idx]].tolist())\n    valid_overlap_idxs.extend(val_data.index[val_data['Patient ID'] == patient_overlap[idx]].tolist())\n    \nprint(f'These are the indices of overlapping patients in the training set: ')\nprint(f'{train_overlap_idxs}')\nprint(f'These are the indices of overlapping patients in the validation set: ')\nprint(f'{valid_overlap_idxs}')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:06.980659Z","iopub.execute_input":"2023-11-06T18:45:06.980971Z","iopub.status.idle":"2023-11-06T18:45:07.013305Z","shell.execute_reply.started":"2023-11-06T18:45:06.980947Z","shell.execute_reply":"2023-11-06T18:45:07.012383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the overlapping patients from the validation set and add them to the training set\n\n# Get the overlapping rows from the validation set\noverlapping_rows = val_data.loc[valid_overlap_idxs]\n\nval_data.drop(valid_overlap_idxs, inplace=True)\n\n\n# Add the overlapping rows to the training set\ntrain_data = pd.concat([train_data, overlapping_rows])\n\n# Reset the indices of the updated training set\ntrain_data.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:07.014382Z","iopub.execute_input":"2023-11-06T18:45:07.014689Z","iopub.status.idle":"2023-11-06T18:45:07.023872Z","shell.execute_reply.started":"2023-11-06T18:45:07.014650Z","shell.execute_reply":"2023-11-06T18:45:07.023002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check that everything worked as planned by rerunning the patient ID comparison between train and validation sets.","metadata":{}},{"cell_type":"code","source":"# Extract patient id's for the validation set\nids_valid = val_data['Patient ID'].values\n# Create a \"set\" datastructure of the validation set id's to identify unique id's\nids_valid_set = set(ids_valid)\nprint(f'There are {len(ids_valid_set)} unique Patient IDs in the validation set')\n\n# Identify patient overlap by looking at the intersection between the sets\npatient_overlap = list(ids_train_set.intersection(ids_valid_set))\nn_overlap = len(patient_overlap)\nprint(f'There are {n_overlap} Patient IDs in both the training and validation sets')","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:07.025065Z","iopub.execute_input":"2023-11-06T18:45:07.025398Z","iopub.status.idle":"2023-11-06T18:45:07.034604Z","shell.execute_reply.started":"2023-11-06T18:45:07.025366Z","shell.execute_reply":"2023-11-06T18:45:07.033847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Because we're going to resize the images to 320 x 320, we also need to apply the same logic to the positions defining the regions** ","metadata":{}},{"cell_type":"code","source":"\n\nIMAGE_SIZE = 320\ntrain_data['x0'] = train_data['Bbox [x'] *  IMAGE_SIZE /1024\ntrain_data['y0'] = train_data['y'] *  IMAGE_SIZE / 1024\ntrain_data['w0'] = train_data['w'] *  IMAGE_SIZE /1024 \ntrain_data['h0'] = train_data['h]'] *  IMAGE_SIZE /1024\n\nval_data['x0'] = val_data['Bbox [x'] *  IMAGE_SIZE /1024\nval_data['y0'] = val_data['y'] *  IMAGE_SIZE / 1024\nval_data['w0'] = val_data['w'] *  IMAGE_SIZE /1024 \nval_data['h0'] = val_data['h]'] *  IMAGE_SIZE /1024","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:07.035568Z","iopub.execute_input":"2023-11-06T18:45:07.035881Z","iopub.status.idle":"2023-11-06T18:45:07.053331Z","shell.execute_reply.started":"2023-11-06T18:45:07.035856Z","shell.execute_reply":"2023-11-06T18:45:07.052473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[['path','x0','y0','h0','w0']]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:07.054398Z","iopub.execute_input":"2023-11-06T18:45:07.054733Z","iopub.status.idle":"2023-11-06T18:45:07.072588Z","shell.execute_reply.started":"2023-11-06T18:45:07.054701Z","shell.execute_reply":"2023-11-06T18:45:07.071657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models Implementation","metadata":{}},{"cell_type":"markdown","source":"In our work we'll use mainly **Intersection over Union (IoU)** but also Accuracy , Validation and training Loss\nIoU metric in object detection evaluates the degree of overlap between the ground(gt) truth and prediction(pd). The ground truth and the prediction are shape-rectangular box .\nDiagrammatically, IoU is defined as follows (the area of the intersection divided by the area of union between ground-truth and predicted box.\n\n","metadata":{}},{"cell_type":"code","source":"from keras.utils import Sequence\nfrom keras.backend import epsilon\n\ndef loss(gt,pred):\n    intersections = 0\n    unions = 0\n    gt = tf.cast(gt, tf.float32)  # Convert to float32 explicitly\n    pred = tf.cast(pred, tf.float32)  # Convert to float32 explicitly\n    diff_width = np.minimum(gt[:,0] + gt[:,2], pred[:,0] + pred[:,2]) - np.maximum(gt[:,0], pred[:,0])\n    diff_height = np.minimum(gt[:,1] + gt[:,3], pred[:,1] + pred[:,3]) - np.maximum(gt[:,1], pred[:,1])\n    intersection = diff_width * diff_height\n    \n    # Compute union\n    area_gt = gt[:,2] * gt[:,3]\n    area_pred = pred[:,2] * pred[:,3]\n    union = area_gt + area_pred - intersection\n\n#     Compute intersection and union over multiple boxes\n    for j, _ in enumerate(union):\n        if union[j] > 0 and intersection[j] > 0 and union[j] >= intersection[j]:\n            intersections += intersection[j]\n            unions += union[j]\n\n    # Compute IOU. Use epsilon to prevent division by zero\n    iou = np.round(intersections / (unions + epsilon()), 4)\n    iou = iou.astype(np.float32)\n    return iou\n\ndef IoU(y_true, y_pred):\n    iou = tf.py_function(loss, [y_true, y_pred], tf.float32)\n    return iou","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:07.073742Z","iopub.execute_input":"2023-11-06T18:45:07.074009Z","iopub.status.idle":"2023-11-06T18:45:07.085641Z","shell.execute_reply.started":"2023-11-06T18:45:07.073986Z","shell.execute_reply":"2023-11-06T18:45:07.084698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VGG19","metadata":{}},{"cell_type":"code","source":"from keras import Model\n\nfrom keras.applications.mobilenet import MobileNet, preprocess_input\n\nfrom keras.applications.vgg19 import VGG19\nfrom keras import regularizers \nfrom keras.regularizers import l2\nfrom keras.layers import Conv2D, Reshape, Dropout , BatchNormalization\n\nmodel = VGG19(include_top=False,input_shape=(320, 320, 3), weights='/kaggle/input/vggweight/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5') \n\n\n\nfor layer in model.layers:\n    layer.trainable = False\n    \nfrom keras.layers import Conv2D , Reshape\nx = model.layers[-1].output\nx = Conv2D(4, kernel_size=10,name=\"CV\")(x)\n#x = BatchNormalization()(x)\nx = Reshape((4,))(x) \n\nmodel = Model(inputs=model.input, outputs=x)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:07.086812Z","iopub.execute_input":"2023-11-06T18:45:07.087122Z","iopub.status.idle":"2023-11-06T18:45:11.480179Z","shell.execute_reply.started":"2023-11-06T18:45:07.087089Z","shell.execute_reply":"2023-11-06T18:45:11.478925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm \ndef read_img(img_path):\n    img = cv2.imread(img_path)\n    img = cv2.resize(img, (320, 320))\n    return img\n\ntrain_img = []\nfor img_path in tqdm(train_data['path'].values):\n    train_img.append(read_img( img_path))\n\nval_img = []\nfor img_path in tqdm(val_data['path'].values):\n    val_img.append(read_img( img_path))\n    \n    \nX_train = np.array(train_img, np.float32) / 255  \nX_val = np.array(val_img, np.float32) / 255  ","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:11.481248Z","iopub.execute_input":"2023-11-06T18:45:11.481503Z","iopub.status.idle":"2023-11-06T18:45:33.966052Z","shell.execute_reply.started":"2023-11-06T18:45:11.481473Z","shell.execute_reply":"2023-11-06T18:45:33.964992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data[['x0','y0','h0','w0']]","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:33.972142Z","iopub.execute_input":"2023-11-06T18:45:33.972460Z","iopub.status.idle":"2023-11-06T18:45:33.988700Z","shell.execute_reply.started":"2023-11-06T18:45:33.972432Z","shell.execute_reply":"2023-11-06T18:45:33.987727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = train_data[['x0','y0','h0','w0']]\ny_val = val_data[['x0','y0','h0','w0']]\nmodel.compile(optimizer='adam',loss='mean_squared_error', metrics=IoU)\ncheckpoint = ModelCheckpoint('VGG_model_1.h5', save_best_only=True, save_weights_only=False , monitor='val_loss' , mode='min', verbose=1 , period=1)\nhistory_1 = model.fit(x= X_train , y=y_train, epochs= 100, validation_data=(X_val,y_val), steps_per_epoch=None,batch_size = 16, verbose=1,callbacks=checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:45:33.989747Z","iopub.execute_input":"2023-11-06T18:45:33.990022Z","iopub.status.idle":"2023-11-06T18:57:58.785589Z","shell.execute_reply.started":"2023-11-06T18:45:33.989999Z","shell.execute_reply":"2023-11-06T18:57:58.784724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history_1.history['loss'])\nplt.plot(history_1.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['training', 'validation'], loc='best')\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:57:58.786932Z","iopub.execute_input":"2023-11-06T18:57:58.787228Z","iopub.status.idle":"2023-11-06T18:57:59.021648Z","shell.execute_reply.started":"2023-11-06T18:57:58.787202Z","shell.execute_reply":"2023-11-06T18:57:59.020674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nimport numpy as np\n\niou_values = []\ntotal_batches = len(validation_generator)\n\nfor i in range(total_batches):\n    batch_images, batch_labels = validation_generator[i]\n    predictions = model.predict(batch_images)\n    \n    iou = IoU(batch_labels, predictions)\n    iou_values.append(iou.numpy())  # Collect IoU values for each batch\n\nmean_iou = np.mean(iou_values)  # Calculate the mean IoU over all batches\nprint(\"Mean IoU:\", mean_iou)\nprint(\"Max IoU:\", np.max(iou_values))\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:57:59.023105Z","iopub.execute_input":"2023-11-06T18:57:59.023870Z","iopub.status.idle":"2023-11-06T18:57:59.030358Z","shell.execute_reply.started":"2023-11-06T18:57:59.023831Z","shell.execute_reply":"2023-11-06T18:57:59.029344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model selection","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Results ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tu peux utiliser cette fonction pour le test sur le meilleur modeles\n\nimport matplotlib.patches as patches\n\ndef plot_predictions(model , sample_df, X , Y , IMAGE_SIZE ):\n    for i in range(sample_df.shape[0]):\n        org_x0 = Y.iloc[i][0]\n        org_y0 = Y.iloc[i][1]\n        org_h0 = Y.iloc[i][2]\n        org_w0 = Y.iloc[i][3]\n\n        image = cv2.resize(X[i], (IMAGE_SIZE, IMAGE_SIZE)) \n        region = model.predict(x=np.array([image]))[0]\n\n        x0 =region[0]  \n        y0 = region[1]\n        h0 = region[2]\n        w0 = region[3]\n        # Display the image\n        fig,ax = plt.subplots(1)\n        ax.imshow(X[i])\n\n        # Create a Rectangle patch\n        # x1-x0 is the width of the bounding box\n        # y1-y0 is the height of the bounding box\n        rect_pred = patches.Rectangle((x0, y0), w0, h0, linewidth=2, edgecolor='r', facecolor='none')\n        rect_org = patches.Rectangle((org_x0, org_y0), org_w0, org_h0, linewidth=2, edgecolor='b', facecolor='none')\n        # Add the patch to the Axes\n        ax.add_patch(rect_pred)\n        ax.add_patch(rect_org)\n\n        # Image coordinates - top-left of the image is (0,0)\n\n        ax.plot(x0, y0, 'o', color='b') # top-left of the bounding box\n        ax.plot(x0+w0, y0+h0, '*', color='c') # bottom-right of the bounding-box\n        ax.set_title(\"ok\")\n        plt.show()\n        print(Y.iloc[i])\n        print(region)\n        #fig.savefig('prediction'+sample_df['Image Index'][i])","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:57:59.031710Z","iopub.execute_input":"2023-11-06T18:57:59.032311Z","iopub.status.idle":"2023-11-06T18:57:59.043919Z","shell.execute_reply.started":"2023-11-06T18:57:59.032277Z","shell.execute_reply":"2023-11-06T18:57:59.043022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsample_df = val_data.head(103)\n\nplot_predictions(model=model , sample_df=sample_df, X=X_val , Y=y_val , IMAGE_SIZE=320 )","metadata":{"execution":{"iopub.status.busy":"2023-11-06T18:57:59.045013Z","iopub.execute_input":"2023-11-06T18:57:59.045287Z","iopub.status.idle":"2023-11-06T18:58:30.520654Z","shell.execute_reply.started":"2023-11-06T18:57:59.045264Z","shell.execute_reply":"2023-11-06T18:58:30.519721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nfolder_path = '/kaggle/working' \nfor filename in os.listdir(folder_path):\n    file_path = os.path.join(folder_path, filename)\n    if os.path.isfile(file_path):\n        os.remove(file_path)\n\n\nfolder_path = '/kaggle/working'\nfor root, dirs, files in os.walk(folder_path, topdown=False):\n    for name in files:\n        file_path = os.path.join(root, name)\n        os.remove(file_path)\n    for name in dirs:\n        dir_path = os.path.join(root, name)\n        os.rmdir(dir_path)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}